{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec10e0fb-fab8-4fcd-a6b3-995873694f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.1\n",
      "  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.5\n",
      "    Uninstalling numpy-2.3.5:\n",
      "      Successfully uninstalled numpy-2.3.5\n",
      "Successfully installed numpy-2.0.2\n",
      "\n",
      "==================================================\n",
      "‚úÖ INSTALL COMPLETE!\n",
      "CRITICAL: Go to 'Kernel' -> 'Restart' in the menu above.\n",
      "Then continue to the next cell.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Force-install a compatible version of NumPy\n",
    "!pip install \"numpy<2.1\" --force-reinstall\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ INSTALL COMPLETE!\")\n",
    "print(\"CRITICAL: Go to 'Kernel' -> 'Restart' in the menu above.\")\n",
    "print(\"Then continue to the next cell.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa75d5d7-4346-4b55-9052-e8ef332b7d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Keys found in this file: ['X', 'y', 'feature_names']\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/home/Capstone_Team78/Dataset/Datasets/UnfilteredSubtypeData.npy')\n",
    "print(f\"üîë Keys found in this file: {data.files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4ff19d-5e88-4433-aaf6-657f145d9ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Genomic Data into RAM...\n",
      "ü§ñ Loading Optimized Model (Stripping legacy Keras arguments)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 16:18:30.539313: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success! Loaded 485577 features and stabilized the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "import os\n",
    "\n",
    "# --- 1. Robust Keras 3 Compatibility Wrapper ---\n",
    "class FixedSpatialDropout1D(SpatialDropout1D):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Keras 3 no longer accepts these legacy arguments in __init__ for this layer\n",
    "        kwargs.pop('trainable', None)\n",
    "        kwargs.pop('noise_shape', None)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "# --- 2. Paths ---\n",
    "DATA_PATH = '/home/Capstone_Team78/Dataset/Datasets/UnfilteredSubtypeData.npy'\n",
    "MODEL_PATH = '/home/Capstone_Team78/Dataset/Models/thyroid-subtype-optimized.h5'\n",
    "\n",
    "# --- 3. Reload Data ---\n",
    "print(\"üìÇ Loading Genomic Data into RAM...\")\n",
    "archive = np.load(DATA_PATH, allow_pickle=True)\n",
    "X_train_sub = archive['X'].astype('float32') \n",
    "y_train_sub = archive['y']\n",
    "cpg_names = archive['feature_names'].tolist()\n",
    "\n",
    "# --- 4. Reload Model with Custom Object Mapping ---\n",
    "print(\"ü§ñ Loading Optimized Model (Stripping legacy Keras arguments)...\")\n",
    "custom_objects = {'SpatialDropout1D': FixedSpatialDropout1D}\n",
    "\n",
    "# loading the 92% accuracy model for SHAP\n",
    "final_model_v2 = tf.keras.models.load_model(\n",
    "    MODEL_PATH, \n",
    "    custom_objects=custom_objects, \n",
    "    compile=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Success! Loaded {X_train_sub.shape[1]} features and stabilized the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35de2d9-4897-4a2a-aaf0-665fc8131aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Creating background baseline...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Create a stable background baseline (200 samples)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# We use 200 because it provides a statistically significant 'average' state\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# for the model to compare individual patients against.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìâ Creating background baseline...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m background_indices = np.random.choice(\u001b[43mX_train_sub\u001b[49m.shape[\u001b[32m0\u001b[39m], \u001b[32m200\u001b[39m, replace=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     11\u001b[39m background_data = X_train_sub[background_indices]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 2. Initialize the DeepExplainer\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_sub' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create a stable background baseline (200 samples)\n",
    "# We use 200 because it provides a statistically significant 'average' state\n",
    "# for the model to compare individual patients against.\n",
    "print(\"üìâ Creating background baseline...\")\n",
    "background_indices = np.random.choice(X_train_sub.shape[0], 200, replace=False)\n",
    "background_data = X_train_sub[background_indices]\n",
    "\n",
    "# 2. Initialize the DeepExplainer\n",
    "print(\"‚è≥ Initializing SHAP DeepExplainer...\")\n",
    "explainer = shap.DeepExplainer(final_model_v2, background_data)\n",
    "\n",
    "# 3. Calculate SHAP values for 50 samples\n",
    "# This will likely take 5-12 minutes on your CPU. \n",
    "print(\"üîç Calculating SHAP values (Sit tight, this is heavy lifting)...\")\n",
    "# We explain 50 samples to get a robust distribution of feature importance\n",
    "shap_values = explainer.shap_values(X_train_sub[:50])\n",
    "\n",
    "# 4. Visualization for Subtype 1 (The minority class with 91% recall)\n",
    "# This plot is the \"Gold Standard\" visual for a medical AI capstone.\n",
    "plt.figure(figsize=(14, 10))\n",
    "shap.summary_plot(\n",
    "    shap_values[1], \n",
    "    X_train_sub[:50], \n",
    "    feature_names=cpg_names, \n",
    "    max_display=30, \n",
    "    plot_type=\"dot\",\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"Top 30 Methylation Markers Driving Subtype Detection\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 5. Save the Results\n",
    "# This creates a CSV you can reference in your final report\n",
    "vals = np.abs(shap_values[1]).mean(0)\n",
    "top_biomarkers = pd.DataFrame(list(zip(cpg_names, vals)), columns=['CpG_Site','Importance'])\n",
    "top_biomarkers.sort_values(by=['Importance'], ascending=False, inplace=True)\n",
    "top_biomarkers.to_csv('top_thyroid_biomarkers.csv', index=False)\n",
    "\n",
    "print(\"\\nüß¨ Top 10 Biological Markers Identified:\")\n",
    "print(top_biomarkers.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d1d5f-14e2-496a-94bb-37b6cdec7890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 16:23:21.704969: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-02-14 16:23:21.712173: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-14 16:23:21.984969: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-14 16:23:22.875894: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-14 16:23:22.877325: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Model and Feature Names...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Capstone_Team78/venv/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2026-02-14 16:23:24.225717: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 485577 features into 128GB RAM.\n",
      "‚è≥ Initializing DeepExplainer (using your 32 CPU threads)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Capstone_Team78/venv/lib/python3.12/site-packages/shap/explainers/_deep/deep_tf.py:94: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# 1. Keras 3 Compatibility Wrapper (Fixes 'trainable' and 'noise_shape' errors)\n",
    "class FixedSpatialDropout1D(SpatialDropout1D):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs.pop('trainable', None)\n",
    "        kwargs.pop('noise_shape', None)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "# 2. Paths (Verified from your system)\n",
    "DATA_PATH = '/home/Capstone_Team78/Dataset/Datasets/UnfilteredSubtypeData.npy'\n",
    "MODEL_PATH = '/home/Capstone_Team78/Dataset/Models/thyroid-subtype-optimized.h5'\n",
    "\n",
    "# 3. Memory-Safe Loading\n",
    "print(\"üìÇ Loading Model and Feature Names...\")\n",
    "archive = np.load(DATA_PATH, allow_pickle=True)\n",
    "cpg_names = archive['feature_names'].tolist()\n",
    "custom_objects = {'SpatialDropout1D': FixedSpatialDropout1D}\n",
    "\n",
    "# Loading the 92% accuracy model for inference\n",
    "model = tf.keras.models.load_model(MODEL_PATH, custom_objects=custom_objects, compile=False)\n",
    "\n",
    "# 4. Load Genomic Features\n",
    "X_full = archive['X'].astype('float32')\n",
    "print(f\"‚úÖ Loaded {X_full.shape[1]} features into 128GB RAM.\")\n",
    "\n",
    "# 5. Lean Background Baseline\n",
    "# 50 samples is the \"Sweet Spot\" for i9 CPUs to stay fast and memory-stable\n",
    "bg_indices = np.random.choice(X_full.shape[0], 50, replace=False)\n",
    "background_data = X_full[bg_indices]\n",
    "\n",
    "# 6. Initialize Explainer\n",
    "print(\"‚è≥ Initializing DeepExplainer (using your 32 CPU threads)...\")\n",
    "explainer = shap.DeepExplainer(model, background_data)\n",
    "\n",
    "# 7. Batch-Processing (10 samples per batch to prevent RAM spikes)\n",
    "print(\"üîç Calculating SHAP values in batches of 10...\")\n",
    "all_shap_values = []\n",
    "num_to_explain = 30 # We explain 30 samples for a statistically significant summary\n",
    "\n",
    "for i in range(0, num_to_explain, 10):\n",
    "    print(f\"   - Processing batch {i//10 + 1}/3...\")\n",
    "    batch = X_full[i:i+10]\n",
    "    batch_shap = explainer.shap_values(batch)\n",
    "    all_shap_values.append(batch_shap)\n",
    "    gc.collect() # Manually clearing memory after each batch\n",
    "\n",
    "# 8. Consolidate for Subtype 1 (91% recall class)\n",
    "final_shap_values = np.concatenate([v[1] for v in all_shap_values], axis=0)\n",
    "X_display = X_full[:num_to_explain]\n",
    "\n",
    "# 9. Visualization\n",
    "print(\"üìä Generating Clinical Summary Plot...\")\n",
    "plt.figure(figsize=(14, 10))\n",
    "shap.summary_plot(\n",
    "    final_shap_values, \n",
    "    X_display, \n",
    "    feature_names=cpg_names, \n",
    "    max_display=20, \n",
    "    plot_type=\"dot\",\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"Top 20 Methylation Biomarkers for Thyroid Subtype\", fontsize=16)\n",
    "plt.savefig('thyroid_shap_summary.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 10. Save Top Biomarkers to CSV for Capstone Report\n",
    "vals = np.abs(final_shap_values).mean(0)\n",
    "top_biomarkers = pd.DataFrame(list(zip(cpg_names, vals)), columns=['CpG_Site','SHAP_Importance'])\n",
    "top_biomarkers.sort_values(by=['SHAP_Importance'], ascending=False, inplace=True)\n",
    "top_biomarkers.to_csv('top_thyroid_biomarkers.csv', index=False)\n",
    "\n",
    "print(\"\\nüß¨ SUCCESS: Top 10 Biological Markers Saved to CSV!\")\n",
    "print(top_biomarkers.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281ee7d1-7d33-4237-9936-e00e1d4052dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 16:52:47.189442: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-02-14 16:52:47.196989: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-14 16:52:47.458820: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-14 16:52:48.316480: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-14 16:52:48.317835: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Filtering Features...\n",
      "Adapting Model for 50k features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Capstone_Team78/venv/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2026-02-14 16:52:50.503826: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Initializing DeepExplainer (Reduced to 50,000 features)...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
      "üîç Calculating SHAP values...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1559f0c133d04be48e529d5db8846983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# 7. Visualization\u001b[39;00m\n\u001b[32m     60\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpg_names_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_display\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/Capstone_Team78/venv/lib/python3.12/site-packages/shap/plots/_beeswarm.py:664\u001b[39m, in \u001b[36msummary_legacy\u001b[39m\u001b[34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale, rng)\u001b[39m\n\u001b[32m    659\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    660\u001b[39m             shape_msg + \u001b[33m\"\u001b[39m\u001b[33m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    661\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    662\u001b[39m         )\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m num_features == features.shape[\u001b[32m1\u001b[39m], shape_msg\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    667\u001b[39m     feature_names = np.array([labels[\u001b[33m\"\u001b[39m\u001b[33mFEATURE\u001b[39m\u001b[33m\"\u001b[39m] % \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[31mAssertionError\u001b[39m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# 1. Keras 3 Compatibility Wrapper\n",
    "class FixedSpatialDropout1D(SpatialDropout1D):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs.pop('trainable', None)\n",
    "        kwargs.pop('noise_shape', None)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "# 2. Paths\n",
    "DATA_PATH = '/home/Capstone_Team78/Dataset/Datasets/UnfilteredSubtypeData.npy'\n",
    "MODEL_PATH = '/home/Capstone_Team78/Dataset/Models/thyroid-subtype-optimized.h5'\n",
    "\n",
    "# 3. Load Data & Filter Features (Crucial Step)\n",
    "print(\"Loading and Filtering Features...\")\n",
    "archive = np.load(DATA_PATH, allow_pickle=True)\n",
    "X_raw = archive['X'].astype('float32')\n",
    "cpg_names_raw = np.array(archive['feature_names'])\n",
    "\n",
    "# Keep only the top 50,000 features with the highest variance\n",
    "# These are the sites that show the most difference between cancer subtypes\n",
    "variances = np.var(X_raw, axis=0)\n",
    "top_indices = np.argsort(variances)[-50000:] \n",
    "\n",
    "X_filtered = X_raw[:, top_indices]\n",
    "cpg_names_filtered = cpg_names_raw[top_indices].tolist()\n",
    "\n",
    "# 4. Reload Model and Adapt Architecture\n",
    "# Note: We must slice the model's weights to match the 50k inputs\n",
    "print(\"Adapting Model for 50k features...\")\n",
    "custom_objects = {'SpatialDropout1D': FixedSpatialDropout1D}\n",
    "full_model = tf.keras.models.load_model(MODEL_PATH, custom_objects=custom_objects, compile=False)\n",
    "\n",
    "# 5. Initialize SHAP with Filtered Data\n",
    "print(\"‚è≥ Initializing DeepExplainer (Reduced to 50,000 features)...\")\n",
    "bg_indices = np.random.choice(X_filtered.shape[0], 50, replace=False)\n",
    "background_data = X_filtered[bg_indices]\n",
    "\n",
    "# We use a custom function to handle the feature slicing for the explainer\n",
    "def model_predict_filtered(data):\n",
    "    # This pads the 50k features back to 485k with zeros so the model can read it\n",
    "    full_input = np.zeros((data.shape[0], 485577), dtype='float32')\n",
    "    full_input[:, top_indices] = data\n",
    "    return full_model.predict(full_input)\n",
    "\n",
    "# Using KernelExplainer here as it is much more memory-stable than DeepExplainer\n",
    "explainer = shap.KernelExplainer(model_predict_filtered, background_data)\n",
    "\n",
    "# 6. Calculate SHAP for 10 samples (Very Safe)\n",
    "print(\"üîç Calculating SHAP values...\")\n",
    "shap_values = explainer.shap_values(X_filtered[:10], nsamples=100)\n",
    "\n",
    "# 7. Visualization\n",
    "plt.figure(figsize=(14, 10))\n",
    "shap.summary_plot(shap_values[1], X_filtered[:10], feature_names=cpg_names_filtered, max_display=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2624a21-61c1-4296-942f-c70955dec42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
